{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxI4LLcnZqRN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY3XUmVsqEM1"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D, Conv2DTranspose, Input,Dropout, ReLU,BatchNormalization,Concatenate,LeakyReLU,Identity\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx0TqPJ9TMNT",
        "outputId": "5117d9aa-0285-4c05-aa6a-10adf1e70d79"
      },
      "outputs": [],
      "source": [
        "!wget -nc https://github.com/Sxela/face2comics/releases/download/v2.0.0/face2comics_v2.0.0_by_Sxela_faces.tar\n",
        "!tar --skip-old-files -xf face2comics_v2.0.0_by_Sxela_faces.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmB-OuXmV_du",
        "outputId": "6a4fbff2-62b4-4ba1-c606-ed678354728f"
      },
      "outputs": [],
      "source": [
        "!wget -nc https://github.com/Sxela/face2comics/releases/download/v2.0.0/face2comics_v2.0.0_by_Sxela_comics.tar\n",
        "!tar --skip-old-files -xf face2comics_v2.0.0_by_Sxela_comics.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo9EnaUwPh7Y"
      },
      "outputs": [],
      "source": [
        "y_folder = \"comics\"\n",
        "x_folder = \"faces\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LHZoVLgPh7Y"
      },
      "outputs": [],
      "source": [
        "x_files = sorted([os.path.join(x_folder, fname) for fname in os.listdir(x_folder) if fname.endswith(\".jpg\")])\n",
        "y_files = sorted([os.path.join(y_folder, fname) for fname in os.listdir(y_folder) if fname.endswith(\".jpg\")])\n",
        "\n",
        "assert len(x_files) == len(y_files), \"Number of files in each folder must be the same\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASPpvdA7Ph7Y"
      },
      "outputs": [],
      "source": [
        "img_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-ixxpNMPh7Y"
      },
      "outputs": [],
      "source": [
        "# Function to load and preprocess images\n",
        "def load_image(file_path):\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [img_size, img_size])\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image - 127.5) / 127.5\n",
        "    return image\n",
        "\n",
        "# Function to load and preprocess paired images\n",
        "def load_pair(x_path, y_path):\n",
        "    x_image = load_image(x_path)\n",
        "    y_image = load_image(y_path)\n",
        "    return x_image, y_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "6XQj3MRCPh7Z",
        "outputId": "39fca963-8916-41e6-d402-ab917851030d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow((load_image(x_files[0]) +1)/2)\n",
        "plt.title(\"Real Image\")\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(load_image(y_files[0]))\n",
        "plt.title(\"Comic Book Image\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsIlH8BPPh7Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCzrUfmnPh7Z",
        "outputId": "c36a59d5-51d0-4b79-bc6e-9383741f730a"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(x_files, y_files, test_size=0.2, random_state=42)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.125, random_state=42)\n",
        "\n",
        "len(X_train),len(X_val),len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDu5NVFRPh7Z"
      },
      "outputs": [],
      "source": [
        "def create_dataset(x_files, y_files,batch_size=16,is_train=False):\n",
        "    # Create a TensorFlow dataset from the file paths\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_files, y_files))\n",
        "\n",
        "    # Map the file paths to images\n",
        "    dataset = dataset.map(lambda x, y: tf.py_function(load_pair, [x, y], [tf.float32, tf.float32]))\n",
        "\n",
        "    if is_train: dataset = dataset.shuffle(1000)\n",
        "\n",
        "    dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "train_dataset = create_dataset(X_train, Y_train,is_train=True)\n",
        "test_dataset = create_dataset(X_test, Y_test)\n",
        "val_dataset = create_dataset(X_val, Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3EVU-sQfUxs"
      },
      "outputs": [],
      "source": [
        "def rmse(y_true, y_pred):\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
        "\n",
        "def psnr(y_true, y_pred):\n",
        "    max_pixel = 1.0\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=max_pixel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntFy2-9fPh7a"
      },
      "outputs": [],
      "source": [
        "def CK(filters, kernel_size=(4, 4), strides=(2, 2), padding='same', use_batch_norm=True, downsample=True):\n",
        "    conv = Conv2D               if downsample       else Conv2DTranspose\n",
        "    norm = BatchNormalization   if use_batch_norm   else Identity\n",
        "    actf = LeakyReLU(0.2)       if downsample       else ReLU()\n",
        "\n",
        "    def layer(x):\n",
        "        x = conv(filters, kernel_size, strides=strides, padding=padding)(x)\n",
        "        x = norm()(x)\n",
        "        x = actf(x)\n",
        "        return x\n",
        "    return layer\n",
        "\n",
        "def CDK(filters, kernel_size=(4, 4), strides=(2, 2), padding='same', use_batch_norm=True, downsample=True,dropout_rate=0.5):\n",
        "    conv = Conv2D               if downsample       else Conv2DTranspose\n",
        "    norm = BatchNormalization   if use_batch_norm   else Identity\n",
        "    actf = ReLU()\n",
        "\n",
        "    def layer(x):\n",
        "        x = conv(filters, kernel_size, strides=strides, padding=padding)(x)\n",
        "        x = norm()(x)\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "        x = actf(x)\n",
        "        return x\n",
        "    return layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaKqxEIRPh7a"
      },
      "outputs": [],
      "source": [
        "def generator(input_nc, output_nc, ngf, num_blocks=1, num_downsample=3):\n",
        "    inputs = Input(shape=(img_size, img_size, input_nc))\n",
        "    x = inputs\n",
        "\n",
        "    # Initial convolutional layers\n",
        "    x = CK(ngf,use_batch_norm=False)(x)\n",
        "\n",
        "    # Contracting path\n",
        "    skips = []\n",
        "    for i in range(num_downsample + num_blocks - 1):\n",
        "        expo = min(i+1,num_downsample)\n",
        "        x = CK(ngf*(2**(expo)))(x)\n",
        "        skips.append(x)\n",
        "\n",
        "    skips = list(reversed(skips))\n",
        "    for skip in skips[:num_blocks-1]:\n",
        "        x = Concatenate()([x, skip])\n",
        "        x = CDK(ngf*(2**(num_downsample)),downsample=False)(x)\n",
        "\n",
        "    for skip in skips[num_blocks-1:]:\n",
        "        x = Concatenate()([x, skip])\n",
        "        x = CK(ngf * (2 ** i),downsample=False)(x)\n",
        "\n",
        "    output = Conv2DTranspose(output_nc, (4, 4), activation='tanh',padding=\"same\",strides=(2, 2))(x)\n",
        "    return Model(inputs=inputs, outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifmqjVREPh7a"
      },
      "outputs": [],
      "source": [
        "def discriminator(input_nc,output_nc, ngf, num_blocks=1, num_downsample=3):\n",
        "\n",
        "    inp = Input(shape=[img_size, img_size, input_nc], name='input_image')\n",
        "    tar = Input(shape=[img_size, img_size, output_nc], name='target_image')\n",
        "\n",
        "    x = Concatenate()([inp, tar])\n",
        "\n",
        "    # Initial convolutional layers\n",
        "    x = CK(ngf,use_batch_norm=False)(x)\n",
        "\n",
        "    # Contracting path\n",
        "    for i in range(num_downsample):\n",
        "        x = CK(ngf*(2**(i+1)))(x)\n",
        "\n",
        "    output = Conv2D(1, (4, 4), activation='sigmoid',padding=\"same\",strides=(2, 2))(x)\n",
        "    return Model(inputs=[inp, tar], outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piRHsksUPh7a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzMGqadlPh7a"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    cross_entropy = BinaryCrossentropy(from_logits=False)\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    cross_entropy = BinaryCrossentropy(from_logits=False)\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def l1_loss(real_image, generated_image):\n",
        "    return tf.reduce_mean(tf.abs(real_image - generated_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4JhxQ_aPh7a"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = Adam(2e-4, beta_1=0.5,beta_2=0.999)\n",
        "discriminator_optimizer = Adam(2e-4, beta_1=0.5,beta_2=0.999)\n",
        "LAMBDA = 100\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(input_image, target_image, generator, discriminator):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_image = generator(input_image, training=True)\n",
        "\n",
        "        real_output = discriminator([input_image, target_image], training=True)\n",
        "        fake_output = discriminator([input_image, generated_image], training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output) + LAMBDA*l1_loss(target_image, generated_image)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq7p4d-uPh7a"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(validation_dataset, generator_model, discriminator_model):\n",
        "    # Initialize accumulators for metrics\n",
        "    val_gen_loss_total = 0\n",
        "    val_rmse_total = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Iterate over the validation dataset\n",
        "    for batch in validation_dataset:\n",
        "        input_image, target_image = batch\n",
        "\n",
        "        # Generate images using the generator model\n",
        "        generated_image = generator_model(input_image, training=False)\n",
        "\n",
        "        # Compute losses\n",
        "        val_gen_loss = generator_loss(discriminator_model([input_image, target_image], training=False)) + l1_loss(target_image, generated_image)\n",
        "        val_rmse = rmse(target_image, generated_image)\n",
        "\n",
        "        # Accumulate metrics\n",
        "        val_gen_loss_total += val_gen_loss\n",
        "        val_rmse_total += val_rmse\n",
        "        num_batches += 1\n",
        "\n",
        "    # Compute average metrics\n",
        "    avg_val_gen_loss = val_gen_loss_total / num_batches\n",
        "    avg_val_rmse = val_rmse_total / num_batches\n",
        "\n",
        "    return avg_val_gen_loss, avg_val_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YclNYPmPh7b"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "input_nc = 3  # Number of input channels (e.g., RGB)\n",
        "output_nc = 3  # Number of output channels (e.g., RGB)\n",
        "ngf = 64  # Number of generator filters in first conv layer\n",
        "\n",
        "generator_model     = generator(input_nc, output_nc, ngf, num_blocks=3, num_downsample=4)\n",
        "discriminator_model = discriminator(input_nc,output_nc, ngf, num_blocks=3, num_downsample=4)\n",
        "\n",
        "generator_model.compile(optimizer=generator_optimizer, loss=generator_loss)\n",
        "discriminator_model.compile(optimizer=discriminator_optimizer, loss=discriminator_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bnRFeIAPh7b",
        "outputId": "f4210bbd-c68c-4443-c4a4-0b7cdf0a4f18"
      },
      "outputs": [],
      "source": [
        "generator_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q3MxmFuePh7b",
        "outputId": "96a01320-ad35-448b-dfcb-1796a96d7c7d"
      },
      "outputs": [],
      "source": [
        "plot_model(generator_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlEEJjb7Ph7b",
        "outputId": "1c703e90-2c64-4a6b-d816-64485c31d33f"
      },
      "outputs": [],
      "source": [
        "discriminator_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "84hNUiP3Ph7b",
        "outputId": "216d5578-dc86-4b23-bcba-69e77db4c95d"
      },
      "outputs": [],
      "source": [
        "plot_model(discriminator_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkcLjpdTPh7b"
      },
      "outputs": [],
      "source": [
        "# Lists to store metrics\n",
        "epochs_list = []\n",
        "gen_losses = []\n",
        "disc_losses = []\n",
        "val_gen_losses = []\n",
        "val_rmses = []\n",
        "val_psnrs = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "7L__5NVTPh7c",
        "outputId": "ca634d7b-b91f-4739-e0ae-204ee1d4e4f6"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    gen_loss_total = 0\n",
        "    disc_loss_total = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in train_dataset:\n",
        "        input_image, target_image = batch\n",
        "        gen_loss, disc_loss = train_step(input_image, target_image, generator_model, discriminator_model)\n",
        "\n",
        "        # Accumulate training losses\n",
        "        gen_loss_total += gen_loss.numpy().item()\n",
        "        disc_loss_total += disc_loss.numpy().item()\n",
        "        num_batches += 1\n",
        "\n",
        "    val_gen_loss, val_rmse = evaluate_model(val_dataset, generator_model, discriminator_model)\n",
        "\n",
        "    # Compute average training losses\n",
        "    gen_loss = gen_loss_total / num_batches\n",
        "    disc_loss = disc_loss_total / num_batches\n",
        "\n",
        "    # Collect training losses\n",
        "    epochs_list.append(epoch + 1)\n",
        "    gen_losses.append(gen_loss)\n",
        "    disc_losses.append(disc_loss)\n",
        "\n",
        "    val_gen_losses.append(val_gen_loss.numpy().item())\n",
        "    val_rmses.append(val_rmse.numpy().item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Gen Loss: {gen_loss:.4f}, D Loss: {disc_loss:.4f}\")\n",
        "    # Validation step\n",
        "    print(f\"Val Gen Loss: {val_gen_loss.numpy().item():.4f}, RMSE: {val_rmse.numpy().item():.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZDh3CJePh7c"
      },
      "outputs": [],
      "source": [
        "# Plot metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot Generator and Discriminator Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_list, gen_losses, label='Generator Loss')\n",
        "plt.plot(epochs_list, disc_losses, label='Discriminator Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Losses')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Validation Metrics\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_list, val_gen_losses, label='Validation Gen Loss')\n",
        "plt.plot(epochs_list, val_rmses, label='Validation RMSE')\n",
        "plt.plot(epochs_list, val_psnrs, label='Validation PSNR')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.title('Validation Metrics')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbkPmZm9Ph7d"
      },
      "outputs": [],
      "source": [
        "def display_random_images(val_dataset, generator_model, num_samples=3):\n",
        "    # Get a random batch from the validation dataset\n",
        "    val_dataset = val_dataset.shuffle(buffer_size=len(val_dataset))\n",
        "    iterator = iter(val_dataset)\n",
        "\n",
        "    # Collect a few random samples\n",
        "    input_images = []\n",
        "    target_images = []\n",
        "    predicted_images = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        batch = next(iterator)\n",
        "        input_image, target_image = batch\n",
        "        input_images.append(input_image.numpy()[0])\n",
        "        target_images.append(target_image.numpy()[0])\n",
        "        predicted_image = generator_model(input_image, training=False)\n",
        "        predicted_images.append(predicted_image.numpy()[0])\n",
        "\n",
        "    # Plot the images\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Input image\n",
        "        axes[i, 0].imshow((input_images[i] + 1) / 2)  # Normalize for display\n",
        "        axes[i, 0].set_title(\"Input\")\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        # Target image\n",
        "        axes[i, 1].imshow((target_images[i] + 1) / 2)  # Normalize for display\n",
        "        axes[i, 1].set_title(\"Target\")\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        # Predicted image\n",
        "        axes[i, 2].imshow((predicted_images[i] + 1) / 2)  # Normalize for display\n",
        "        axes[i, 2].set_title(\"Prediction\")\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "display_random_images(val_dataset, generator_model, num_samples=3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
